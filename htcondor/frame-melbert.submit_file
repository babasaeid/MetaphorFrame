####################
#
# Example Job for HTCondor
#
####################

#---------------------------------------------
# Name your batch so it's easy to distinguish in the q.
JobBatchName = "Frame MelBert"

# --------------------------------------------

batch_size = 16
spv_isolate = True
small_mean = False
vua_version = 18
num_train_epoch = 5
frame_mean = False
frame_model = sent_no_mask_ff

# Executable and its arguments
executable    = $ENV(HOME)/.conda/envs/lyc/bin/python
arguments     = $ENV(HOME)/MetaphorFrame/main.py --model_type FrameMelbert --bert_model roberta-base --train_batch_size $(batch_size) --spv_isolate $(spv_isolate) --data_dir /user/HS502/yl02706/MetaphorFrame/data/VUA$(vua_version) --small_mean $(small_mean) --num_train_epoch $(num_train_epoch) --frame_mean $(frame_mean) --frame_model /vol/research/nlg/frame_finder/checkpoints/$(frame_model)

# ---------------------------------------------------
# Universe (vanilla, docker)
universe         = docker
docker_image     = nvidia/cuda:10.2-cudnn7-runtime-ubuntu16.04

# -------------------------------------------------
# Event, out and error logs
log    = c$(cluster).p$(process).$(batch_size).vua$(vua_version).epoch$(num_train_epoch).sm$(small_mean).fmean$(frame_mean).frame-$(frame_model).spi$(spv_isolate).log
output = c$(cluster).p$(process).$(batch_size).vua$(vua_version).epoch$(num_train_epoch).sm$(small_mean).fmean$(frame_mean).frame-$(frame_model).spi$(spv_isolate).out
error  = c$(cluster).p$(process).$(batch_size).vua$(vua_version).epoch$(num_train_epoch).sm$(small_mean).fmean$(frame_mean).frame-$(frame_model).spi$(spv_isolate).error

# -----------------------------------
# File Transfer, Input, Output
should_transfer_files = YES

# Make certain project spaces available in container
# environment = "mount=$ENV(HOME)"
# environment = "mount=$ENV(HOME),/vol/research/nlg,/vol/research/lyc_d"
environment = "mount=/vol/research/nlg,/vol/research/lyc_d"
# environment = "mount='/vol/research/nlg'"
# environment = "mount='/vol/research/lyc_d'"

# -------------------------------------
# Requirements for the Job (Requirements are explained in further detail in example09.submit_file)
# NOTE: HasStornext is not valid on orca.
requirements = (CUDAGlobalMemoryMb > 8000) && (CUDAGlobalMemoryMb <  25000) && \
#              (HasStornext) && \
			   (CUDACapability > 2.0) && (CUDACapability < 8.0)

# --------------------------------------
# Resources
request_GPUs     = 1
# this needs to be specified for the AI@Surrey cluster if requesting a GPU
+GPUMem          = 10000
request_CPUs     = 1
request_memory   = 8G

#This job will complete in less than 1 hour
+JobRunTime = 12

#This job can checkpoint
+CanCheckpoint = true

# -----------------------------------
# Queue commands
queue
